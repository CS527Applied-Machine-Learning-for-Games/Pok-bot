# Pokébot


## Team Members:

Abhilash Pandurangan, ap57160@usc.edu
Aishwarya Mustoori, mustoori@usc.edu
Joseph Badra, jbadra@usc.edu
Mrunal Deshmukh, mndeshmu@usc.edu
Nilay Pachauri, pachauri@usc.edu
Ruicheng Li, ruicheng@usc.edu
Ruoyu Chen, ruoyuche@usc.edu
Tarun Ravikumar, travikum@usc.edu


## Introduction 

Pokémon is a cross-generation game that is centered around creating one's team of six Pokémon and becoming the very best with them. Pokémon Showdown, a Pokémon battling simulator, is the platform that makes it easier for players to theory craft, fight a variety of opponents, and try different battling strategies. In this project, an approach to optimize a player’s decisions is explored in the Single Battle ruleset.

## Goals of the Project

The goals of this project include:

1. To build a PokéBot Agent which chooses the best optimal move each turn, given the current state of both teams using Deep Q Reinforcement Learning.
2. To predict the winning player correctly after each move using human replays data. 
3. To evaluate the bot’s performance with Human Players on the leaderboard.


Website Link: https://cs527applied-machine-learning-for-games.github.io/Pok-bot/

Heroku Application Link: http://usc-pokemon-showdown.herokuapp.com-80.psim.us/


## References:

1.  Poke-env GitHub: https://github.com/hsahovic/poke-env
2.  Pokémon Showdown:  https://Pokémonshowdown.com/

