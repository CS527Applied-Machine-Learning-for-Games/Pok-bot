# Pokébot


## Team Members

1. Abhilash Pandurangan, ap57160@usc.edu
2. Aishwarya Mustoori, mustoori@usc.edu
3. Joseph Badra, jbadra@usc.edu
4. Mrunal Deshmukh, mndeshmu@usc.edu
5. Nilay Pachauri, pachauri@usc.edu
6. Ruicheng Li, ruicheng@usc.edu
7. Ruoyu Chen, ruoyuche@usc.edu
8. Tarun Ravikumar, travikum@usc.edu


## Introduction 

Pokémon is a cross-generation game that is centered around creating one's team of six Pokémon and becoming the very best with them. Pokémon Showdown, a Pokémon battling simulator, is the platform that makes it easier for players to theory craft, fight a variety of opponents, and try different battling strategies. In this project, an approach to optimize a player’s decisions is explored in the Single Battle ruleset.

## Goals of the Project

The goals of this project include:

1. To build a PokéBot Agent which chooses the best optimal move each turn, given the current state of both teams using Deep Q Reinforcement Learning.
2. To predict the winning player correctly after each move using human replays data. 
3. To evaluate the bot’s performance with Human Players on the leaderboard.


Website Link: https://cs527applied-machine-learning-for-games.github.io/Pok-bot/

Heroku Application Link: http://usc-pokemon-showdown.herokuapp.com-80.psim.us/

Google Drive Link for data : https://drive.google.com/drive/folders/1tu7qDDw8NLILY4DnVYujWGTD0fcOlu4a?usp=sharing


## References:

1.  Poke-env GitHub: https://github.com/hsahovic/poke-env
2.  Pokémon Showdown:  https://Pokémonshowdown.com/

